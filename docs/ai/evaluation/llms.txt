# Evaluation Docs

## Evaluation

- [Responsible AI with .NET](https://raw.githubusercontent.com/dotnet/docs/refs/heads/llmstxt/docs/ai/evaluation/responsible-ai.md): Learn what responsible AI is and how you can use .NET to evaluate the safety of your AI apps.
- [The Microsoft.Extensions.AI.Evaluation libraries](https://raw.githubusercontent.com/dotnet/docs/refs/heads/llmstxt/docs/ai/evaluation/libraries.md): Learn about the Microsoft.Extensions.AI.Evaluation libraries, which simplify the process of evaluating the quality and accuracy of responses generated by AI models in .NET intelligent apps.

## Tutorials

- [Quickstart: Evaluate the quality of a response](https://raw.githubusercontent.com/dotnet/docs/refs/heads/llmstxt/docs/ai/evaluation/evaluate-ai-response.md): Learn how to create an MSTest app to evaluate the AI chat response of a language model.
- [Evaluate response quality with caching and reporting](https://raw.githubusercontent.com/dotnet/docs/refs/heads/llmstxt/docs/ai/evaluation/evaluate-with-reporting.md): Create an MSTest app to evaluate the response quality of a language model, add a custom evaluator, and learn how to use the caching and reporting features of Microsoft.Extensions.AI.Evaluation.
- [Evaluate response safety with caching and reporting](https://raw.githubusercontent.com/dotnet/docs/refs/heads/llmstxt/docs/ai/evaluation/evaluate-safety.md): Create an MSTest app that evaluates the content safety of a model's response using the evaluators in the Microsoft.Extensions.AI.Evaluation.Safety package and with caching and reporting.
