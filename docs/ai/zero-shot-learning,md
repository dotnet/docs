---
title: "Zero-shot and few-shot learning"
description: "Learn the use cases for zero-shot and few-shot learning in prompt engineering."
author: catbutler
ms.author: [your Microsoft alias or a team alias]
ms.service: [the approved service name]
ms.topic: concept-article #Don't change.
ms.date: [mm/dd/yyyy]

#customer intent: As a .NET developer, I want to understand how zero-shot and few-shot learning techniques can help me improve my prompt engineering.

---

# Concept - Zero-shot and few-shot learning

This article explains the use of zero-shot learning and few-shot learning in .NET prompt engineering.

GPT model performance benefits from [prompt engineering](prompt-engineering-in-dot-net.md), the practice of giving instructions and examples to a model to refine its output. Zero-shot learning and few-shot learning are techniques that you use to iteratively develop engineered prompts.

Zero-shot learning relies on the model's existing knowledge to generate responses, making it the most cost-effective option for prompt engineering. However, it doesn't increase your model's knowledge. Few-shot learning is more resource-intensive, but it adds to the model's knowledge. 

## Zero-shot learning use cases

This section explains the use cases for zero-shot learning with a GPT model. 

Zero-shot learning is the practice of passing prompts that aren't paired with verbatim completions, although they can be paired with a cue. There are two primary use cases for zero-shot learning:
-  Because it relies on the model's existing knowledge, zero-shot learning is not as resource-intensive as few-shot learning, and it works well with LLMs that have already been fined-tuned on instruction datasets. You might be able to rely solely on zero-shot learning and keep costs relatively low. 
- Zero-shot learning can help you simulate how your app would perform for actual users. This lets you evaluate various aspects of your model's current performance, such as accuracy or precision. In this case, you typically use zero-shot learning to establish a performance baseline and then experiment with few-shot learning to improve performance.

--- Sloan, it's possible to have an LLM generate zero-shot prmopts, but I don't know how it would work in .NET. I'll have to dig around in the APIs and .NET classes to research the question If you have any ideas, this doc could be a lot better if it had info about LLM generation of example prompts in .NET. If not, delete this comment on review and let the MS folks tell us if something's missing. 

## Few-shot learning use cases

This section explains the use cases for few-shot learning with a GPT-model.

Few-shot learning is the practice of passing few-shot prompts (prompts paired with completions) to show your model how to respond. Unlike zero-shot learning, few-shot learning can add to the model's knowledge. It has two primary use cases:
- Because it can add to the model's knowledge, few-shot learning can improve a model's performance. Although this can become expensive, if your LLM isn't fined-tuned yet you won't get good performance with zero-shot prompts. In this case, few-shot learning is necessary if you want to improve performance.
- You can use few-shot learning as a follow-on to zero-shot learning. In this case, you use zero-shot learning to establish a performance baseline, and then experiment with few-shot learning based on the zero-shot prompts you used. This lets you add to the model's knowledge after seeing how it currently responds, so you can iterate and improve performance significantly.   

## Related content

- [Prompt engineering techniques](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering)
- [Related article title](link.md)
- [Related article title](link.md)

--- Add more RLs after more docs are ready  