<Type Name="RecognizedPhrase" FullName="System.Speech.Recognition.RecognizedPhrase">
  <TypeSignature Language="C#" Value="public class RecognizedPhrase" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedPhrase extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedPhrase" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedPhrase" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedPhrase" />
  <TypeSignature Language="F#" Value="type RecognizedPhrase = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Diagnostics.DebuggerDisplay("{Text}")</AttributeName>
    </Attribute>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Contains detailed information, generated by the speech recognizer, about the recognized input.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 This class contains detailed information about words and phrases processed during speech recognition operations, including the following:  
  
-   The <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> property references the <xref:System.Speech.Recognition.Grammar> that the recognizer used to identify the input.  
  
-   The <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the normalized text for the phrase.  
  
-   The <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> property references the semantic information contained in the result. The semantic information is a dictionary of the key names and associated semantic data.  
  
-   The <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedWordUnit> objects that represent each recognized word in the input. Each word unit contains display format, lexical format, and pronunciation information for the corresponding word.  
  
-   The <xref:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits%2A> property contains information about specialized word substitution.  
  
-   The <xref:System.Speech.Recognition.RecognizedPhrase.Homophones%2A> and <xref:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId%2A> properties contain information about recognition alternates that have the same or similar pronunciation.  
  
-   The value of the <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> property  indicates the degree of certainty, assigned by the speech recognizer, that a recognized phrase matches the input.  
  
 The speech recognizer returns recognition results in a <xref:System.Speech.Recognition.RecognitionResult> object, which inherits from <xref:System.Speech.Recognition.RecognizedPhrase>. The recognition result <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects, each of which is a possible match for the input to the recognizer.  
  
   
  
## Examples  
 The following example shows a handler for a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, or <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> event and some of the information associated with the <xref:System.Speech.Recognition.RecognitionResult> object. The <xref:System.Speech.Recognition.RecognitionResult> class derives from the <xref:System.Speech.Recognition.RecognizedPhrase> class.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
  </Docs>
  <Members>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets a value, assigned by the recognizer, that represents the likelihood that a <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> matches a given input.</summary>
        <value>A relative measure of the certainty of correct recognition of a phrase. The value is from 0.0 to 1.0, for low to high confidence, respectively.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Confidence scores do not indicate the absolute likelihood that a phrase was recognized correctly. Instead, confidence scores provide a mechanism for comparing the relative accuracy of multiple recognition alternates for a given input. This facilitates returning the most accurate recognition result. For example, if a recognized phrase has a confidence score of 0.8, this does not mean that the phrase has an 80% chance of being the correct match for the input.  It means that the phrase is more likely to be the correct match for the input than other results that have confidence scores less than 0.8.  
  
 A confidence score on its own is not meaningful unless you have alternative results to compare against, either from the same recognition operation or from previous recognitions of the same input. The values are used to rank alternative candidate phrases returned by the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property on <xref:System.Speech.Recognition.RecognitionResult> objects.  
  
 Confidence values are relative and unique to each recognition engine. Confidence values returned by two different recognition engines cannot be meaningfully compared.  
  
 A speech recognition engine may assign a low confidence score to spoken input for various reasons, including background interference, inarticulate speech, or unanticipated words or word sequences. If your application is using a <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> methods. Confidence thresholds for the shared recognizer, managed by <xref:System.Speech.Recognition.SpeechRecognizer>, are associated with a user profile and stored in the Windows registry. Applications should not write changes to the registry for the properties of the shared recognizer.  
  
 The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property of the <xref:System.Speech.Recognition.RecognitionResult> object contains an ordered collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects, each of which is a possible match for the input to the recognizer. The alternates are ordered from highest to lowest confidence.  
  
   
  
## Examples  
 The following example shows a handler for a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, or <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> event. The example shows information associated with the <xref:System.Speech.Recognition.RecognitionResult> object, some of which is derived from <xref:System.Speech.Recognition.RecognizedPhrase>. The handler displays confidence scores for a recognized phrase as well as for recognition alternates.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="ConstructSmlFromSemantics">
      <MemberSignature Language="C#" Value="public System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics" />
      <MemberSignature Language="VB.NET" Value="Public Function ConstructSmlFromSemantics () As IXPathNavigable" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Xml::XPath::IXPathNavigable ^ ConstructSmlFromSemantics();" />
      <MemberSignature Language="F#" Value="member this.ConstructSmlFromSemantics : unit -&gt; System.Xml.XPath.IXPathNavigable" Usage="recognizedPhrase.ConstructSmlFromSemantics " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Xml.XPath.IXPathNavigable</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Returns a semantic markup language (SML) document for the semantic information in the <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> object.</summary>
        <returns>Returns an SML description of the semantics of the <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> as an <see href="https://msdn.microsoft.com/library/ms256115.aspx">XPath</see> navigable object.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 For information about the semantic markup language (SML), see the [Semantic Markup Language Reference](https://msdn.microsoft.com/library/f9d83443-2cac-49bc-a447-210feda62f5d).  
  
   
  
## Examples  
 In the following example, a method returns a string that contains the SML for the semantics of a recognized phrase.  
  
```  
private string GetSemanticsSML(RecognizedPhrase result)  
{  
  if (result.Semantics.Count > 0)  
  {  
    return result.ConstructSmlFromSemantics().CreateNavigator().OuterXml;  
  }  
  else  
  {  
    return null;  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Grammar">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.Grammar Grammar { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.Grammar Grammar" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammar As Grammar" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::Grammar ^ Grammar { System::Speech::Recognition::Grammar ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammar : System.Speech.Recognition.Grammar" Usage="System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.Grammar</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the <see cref="T:System.Speech.Recognition.Grammar" /> that the speech recognizer used to return the <see cref="T:System.Speech.Recognition.RecognizedPhrase" />.</summary>
        <value>The grammar object that the speech recognizer used to identify the input.</value>
        <remarks>To be added.</remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="HomophoneGroupId">
      <MemberSignature Language="C#" Value="public int HomophoneGroupId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 HomophoneGroupId" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property HomophoneGroupId As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int HomophoneGroupId { int get(); };" />
      <MemberSignature Language="F#" Value="member this.HomophoneGroupId : int" Usage="System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the identifier for the homophone group for the phrase.</summary>
        <value>The identifier for the homophone group for the phrase.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 The speech recognizer assigns a group identifier to all recognition alternates that have the same pronunciation. For each alternate that has a unique pronunciation, the recognizer creates a homophone group. The speech recognizer generates new group of identifiers for each recognition operation, and the identifiers cannot be used to compare alternates from generated from separate recognition operations.  
  
 For example, for a recognition result that contained the alternates "the tale", "the tail", and "the ale", the first two alternates would belong to one homophone group, and the last alternate would be the single member of a second homophone group.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      </Docs>
    </Member>
    <Member MemberName="Homophones">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Homophones { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Homophones" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Homophones As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Homophones { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Homophones : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets a collection of the recognition alternates that have the same pronunciation as this recognized phrase.</summary>
        <value>A read-only collection of the recognition alternates that have the same pronunciation as this recognized phrase.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 This property returns all other recognition alternates that have the same pronunciation as this recognized phrase.  
  
 For example, for a recognition result that contained the alternates, "the tale" and "the tail", the homophones collection for the first alternate, "the tale", would contain the second phrase, "the tail". The homophones collection for the second alternate, "the tail", would contain the first phrase, "the tale".  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      </Docs>
    </Member>
    <Member MemberName="ReplacementWordUnits">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.Collection`1&lt;class System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property ReplacementWordUnits As Collection(Of ReplacementText)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ ReplacementWordUnits { System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.ReplacementWordUnits : System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets information about the text that the speech recognizer changed as part of speech-to-text normalization.</summary>
        <value>A collection of <see cref="T:System.Speech.Recognition.ReplacementText" /> objects that describe sections of text that the speech recognizer replaced when it normalized the recognized input.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 As part of the speech recognition process, the speech recognizer normalizes the recognized input into a display form.  
  
 For example, the spoken input, "twenty five dollars", generates a recognition result where the <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains the words, "twenty", "five", and "dollars", and the <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the phrase, "$25.00". For more information about text normalization, see the <xref:System.Speech.Recognition.ReplacementText> class.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="T:System.Speech.Recognition.ReplacementText" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Semantics">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.SemanticValue Semantics { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.SemanticValue Semantics" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Semantics As SemanticValue" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::SemanticValue ^ Semantics { System::Speech::Recognition::SemanticValue ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Semantics : System.Speech.Recognition.SemanticValue" Usage="System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.SemanticValue</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the semantic information that is associated with the recognized phrase.</summary>
        <value>The semantic information associated with the recognized phrase.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 A speech recognition grammar can include semantic information. When a speech recognizer generates a recognition result for such a grammar, the semantic information might be included in the recognition result, according to the rules of the grammar and the input to the recognizer. For more information about semantic information, see [Understanding Semantic Results](https://msdn.microsoft.com/library/2a9dbd8b-cf6d-42cd-bbb9-ca0b3e534005) and the <xref:System.Speech.Recognition.SemanticResultKey> and <xref:System.Speech.Recognition.SemanticResultValue> classes.  
  
   
  
## Examples  
 The following example defines a method that gets specific semantic information from a recognized phrase. When this method returns, it contains the value for the semantic key, or null if the value was not retrieved. This method checks only for top-level keys. Since the semantic information is contained in a tree of values, lower-level keys must be accessed through the returned semantic value.  
  
```  
static bool TryGetSemanticValue(  
      RecognizedPhrase phrase, string key, out SemanticValue value)  
{  
  value = null;  
  bool found = phrase.Semantics.ContainsKey(key);  
  if (found)  
  {  
    value = phrase.Semantics[key];  
  }  
  
  return found;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SemanticResultKey" />
        <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
        <altmember cref="T:System.Speech.Recognition.SemanticValue" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the normalized text generated by a speech recognizer from recognized input.</summary>
        <value>The normalized text generated by a speech recognizer from recognized input.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 As part of the speech recognition process, the speech recognizer performs speech-to-text normalization of the recognized input into a display form.  
  
 For example, the spoken input, "twenty five dollars", generates a recognition result where the <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains the words, "twenty", "five", and "dollars", and the <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the phrase, "$25.00". For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Words">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt; Words { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedWordUnit&gt; Words" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Words As ReadOnlyCollection(Of RecognizedWordUnit)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ Words { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Words : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the words generated by a speech recognizer from recognized input.</summary>
        <value>The collection of <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> objects generated by a speech recognizer for recognized input.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 This property contains the words produced from the input by the speech recognizer prior to the recognizer's speech-to-text normalization of the result.  
  
 For example, the spoken input, "twenty five dollars", generates a recognition result where the <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains the words, "twenty", "five", and "dollars", and the <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the phrase, "$25.00". For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      </Docs>
    </Member>
  </Members>
</Type>